{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert .bin drawing to .npy drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from random import randint\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_file = open(\"object.txt\", \"r\")\n",
    "objects = object_file.readlines()\n",
    "object_file.close()\n",
    "N_CLASSES = len(objects)\n",
    "CLASSES = {}\n",
    "for idx, obj in enumerate(objects):\n",
    "    CLASSES[idx] = obj.replace('\\n', '')\n",
    "# print(CLASSES)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(file_path):\n",
    "    \"\"\"\n",
    "    Extract the variable from a string in the format npy_data\\{variable}.npy.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: String containing the path.\n",
    "\n",
    "    Returns:\n",
    "    - str: Extracted variable.\n",
    "    \"\"\"\n",
    "    match = re.search(r'npy_data\\\\(.*?)\\.npy', file_path)\n",
    "    if match:\n",
    "        variable = match.group(1)\n",
    "        return variable\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_key_by_value(dictionary, target_value):\n",
    "    \"\"\"\n",
    "    Get the key associated with a specific value in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - dictionary: The input dictionary.\n",
    "    - target_value: The value to search for.\n",
    "\n",
    "    Returns:\n",
    "    - key: The key associated with the target value, or None if not found.\n",
    "    \"\"\"\n",
    "    for key, value in dictionary.items():\n",
    "        if value == target_value:\n",
    "            return key\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparrs = np.load(\"./npy_data/apple.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparrs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random 1000 drawings from each object\n",
    "def load_drawings(root, reshaped=False):\n",
    "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
    "    \n",
    "    data = []\n",
    "    label_data = []\n",
    "    for index, file in enumerate(all_files):\n",
    "        extracted_label = extract_label(file)\n",
    "        np_arrays = np.load(file)\n",
    "        label_arrays = []\n",
    "        if reshaped:\n",
    "            new_arrays = []\n",
    "            new_label_arrays = []\n",
    "            for idx in range(len(np_arrays)):\n",
    "                rot_coeff = randint(0,3)\n",
    "                label_index = get_key_by_value(CLASSES, extracted_label)\n",
    "                if label_index == None:\n",
    "                    continue\n",
    "                # Reshape into a picture 28x28\n",
    "                np_arr = np.reshape(np_arrays[idx] ,(28,28))\n",
    "                # Rotate for better model\n",
    "                np_arr = np.rot90(np_arr, rot_coeff)\n",
    "                # Add another dimension for CNN network\n",
    "                np_arr = np.reshape(np_arr, (28,28,1))\n",
    "                new_arrays.append(np_arr)\n",
    "                new_label_arrays.append(label_index)\n",
    "            np_arrays = new_arrays\n",
    "            label_arrays = new_label_arrays\n",
    "        data.append(np_arrays)\n",
    "        label_data.append(label_arrays)\n",
    "    return data, label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label_data = load_drawings('npy_data', reshaped=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(label_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(nparr):\n",
    "    img = Image.fromarray(nparr.reshape(28,28))\n",
    "    img.show(title=\"visualize array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(data[0][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_lim(np_arrays, label_data_arrays, lim):\n",
    "    lim_arr = []\n",
    "    lim_labels = []\n",
    "    for arr_index in range(len(np_arrays)):\n",
    "        i = 0\n",
    "        data_array = np_arrays[arr_index]\n",
    "        label_array = label_data_arrays[arr_index]\n",
    "        for index in range(len(data_array)):\n",
    "            if i == lim:\n",
    "                break\n",
    "            lim_arr.append(data_array[index])\n",
    "            lim_labels.append(label_array[index])\n",
    "            i += 1\n",
    "    return lim_arr, lim_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = set_lim(data, label_data, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(data))\n",
    "# print(len(labels))\n",
    "# print(labels[2000:2010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(nparr):\n",
    "    return np.interp(nparr, [0, 255], [-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(nparr):\n",
    "    return np.interp(nparr, [-1, 1], [0, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = normalize(data)\n",
    "\n",
    "# print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.        ],\n",
       "         [ 0.74117647],\n",
       "         [ 1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-0.84313725],\n",
       "         [-0.27843137],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]]],\n",
       "\n",
       "\n",
       "       [[[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]]],\n",
       "\n",
       "\n",
       "       [[[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]]],\n",
       "\n",
       "\n",
       "       [[[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]]],\n",
       "\n",
       "\n",
       "       [[[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]],\n",
       "\n",
       "        [[-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         ...,\n",
       "         [-1.        ],\n",
       "         [-1.        ],\n",
       "         [-1.        ]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = tts(data, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, N_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "\n",
    "def conv(classes, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv(classes=N_CLASSES, input_shape=(28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 2s 8ms/step - loss: 0.9022 - accuracy: 0.6640\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.4203 - accuracy: 0.8665\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.3028 - accuracy: 0.9035\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.2415 - accuracy: 0.9205\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.2074 - accuracy: 0.9310\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.1844 - accuracy: 0.9402\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.1553 - accuracy: 0.9495\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.1453 - accuracy: 0.9515\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1346 - accuracy: 0.9532\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1208 - accuracy: 0.9607\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.1109 - accuracy: 0.9640\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.0994 - accuracy: 0.9653\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 4s 31ms/step - loss: 0.1021 - accuracy: 0.9630\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0913 - accuracy: 0.9678\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.0931 - accuracy: 0.9668\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0737 - accuracy: 0.9753\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0755 - accuracy: 0.9728\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.0736 - accuracy: 0.9737\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0680 - accuracy: 0.9778\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0663 - accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b5081b9ff0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(np.array(x_train), np.array(Y_train), batch_size=32, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(np.array(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.19999999999999\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    if np.argmax(pred[i]) == y_test[i]:\n",
    "        score+=1\n",
    "\n",
    "acc = ((score+0.0)/len(pred)*100)\n",
    "print(\"Accuracy: {acc}\".format(acc = ((score+0.0)/len(pred)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Get the current date and time\n",
    "current_time = datetime.now()\n",
    "\n",
    "# Format the date and time as a string (e.g., \"2022-01-01_12-30-45\")\n",
    "formatted_time = current_time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Combine the formatted time with a base file name\n",
    "base_file_name = \"./model/doodle\"\n",
    "\n",
    "file_name_with_timestamp = f\"{base_file_name}.h5\"\n",
    "\n",
    "model.save(file_name_with_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"./model/doodle.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_numpy_array(file_path):\n",
    "    \"\"\"\n",
    "    Load a NumPy array from a file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: File path to load the array from.\n",
    "\n",
    "    Returns:\n",
    "    - numpy array: Loaded NumPy array.\n",
    "    \"\"\"\n",
    "    loaded_array = np.load(file_path)\n",
    "    return loaded_array\n",
    "\n",
    "# # Example Usage:\n",
    "# file_path = \"./user-data.npy\"\n",
    "# loaded_array = load_numpy_array(file_path)\n",
    "# print(\"Loaded NumPy array:\")\n",
    "# visualize(denormalize(loaded_array))\n",
    "# print(model.predict(loaded_array))\n",
    "# pred = CLASSES[np.argmax(model.predict(loaded_array))]\n",
    "# print(\"Predicted:\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def visualize_and_predict():\n",
    "    \"selects a random test case and shows the object, the prediction and the expected result\"\n",
    "    n = randint(0, len(x_test))\n",
    "    visualize(denormalize(np.reshape(x_test[n], (28, 28))))\n",
    "    pred = CLASSES[np.argmax(model.predict(np.array([x_test[n]])))]\n",
    "    actual = CLASSES[y_test[n]]\n",
    "    print(\"Actual:\", actual)\n",
    "    print(\"Predicted:\", pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

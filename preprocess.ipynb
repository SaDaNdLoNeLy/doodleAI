{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert .bin drawing to .npy drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'triangle', 1: 'circle', 2: 'square', 3: 'apple', 4: 'banana', 5: 'diamond'}\n"
     ]
    }
   ],
   "source": [
    "object_file = open(\"object.txt\", \"r\")\n",
    "objects = object_file.readlines()\n",
    "object_file.close()\n",
    "N_CLASSES = len(objects)\n",
    "CLASSES = {}\n",
    "for idx, obj in enumerate(objects):\n",
    "    CLASSES[idx] = obj.replace('\\n', '')\n",
    "print(CLASSES)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(file_path):\n",
    "    \"\"\"\n",
    "    Extract the variable from a string in the format npy_data\\{variable}.npy.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: String containing the path.\n",
    "\n",
    "    Returns:\n",
    "    - str: Extracted variable.\n",
    "    \"\"\"\n",
    "    match = re.search(r'npy_data\\\\(.*?)\\.npy', file_path)\n",
    "    if match:\n",
    "        variable = match.group(1)\n",
    "        return variable\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_key_by_value(dictionary, target_value):\n",
    "    \"\"\"\n",
    "    Get the key associated with a specific value in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - dictionary: The input dictionary.\n",
    "    - target_value: The value to search for.\n",
    "\n",
    "    Returns:\n",
    "    - key: The key associated with the target value, or None if not found.\n",
    "    \"\"\"\n",
    "    for key, value in dictionary.items():\n",
    "        if value == target_value:\n",
    "            return key\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random 1000 drawings from each object\n",
    "def load_drawings(root, reshaped=False):\n",
    "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
    "    \n",
    "    data = []\n",
    "    label_data = []\n",
    "    for index, file in enumerate(all_files):\n",
    "        extracted_label = extract_label(file)\n",
    "        np_arrays = np.load(file)\n",
    "        label_arrays = []\n",
    "        if reshaped:\n",
    "            new_arrays = []\n",
    "            new_label_arrays = []\n",
    "            for idx in range(len(np_arrays)):\n",
    "                label_index = get_key_by_value(CLASSES, extracted_label)\n",
    "                if label_index == None:\n",
    "                    continue\n",
    "                np_arr = np.reshape(np_arrays[idx] ,(28,28,1))\n",
    "                new_arrays.append(np_arr)\n",
    "                new_label_arrays.append(label_index)\n",
    "            np_arrays = new_arrays\n",
    "            label_arrays = new_label_arrays\n",
    "        data.append(np_arrays)\n",
    "        label_data.append(label_arrays)\n",
    "    return data, label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label_data = load_drawings('npy_data', reshaped=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(label_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(nparr):\n",
    "    img = Image.fromarray(nparr.reshape(28,28))\n",
    "    img.show(title=\"visualize array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_lim(np_arrays, label_data_arrays, lim):\n",
    "    lim_arr = []\n",
    "    lim_labels = []\n",
    "    for arr_index in range(len(np_arrays)):\n",
    "        i = 0\n",
    "        data_array = np_arrays[arr_index]\n",
    "        label_array = label_data_arrays[arr_index]\n",
    "        for index in range(len(data_array)):\n",
    "            if i == lim:\n",
    "                break\n",
    "            lim_arr.append(data_array[index])\n",
    "            lim_labels.append(label_array[index])\n",
    "            i += 1\n",
    "    return lim_arr, lim_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = set_lim(data, label_data, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "30000\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(labels))\n",
    "print(labels[2000:2010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(nparr):\n",
    "    return np.interp(nparr, [0, 255], [-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(nparr):\n",
    "    return np.interp(nparr, [-1, 1], [0, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "data = normalize(data)\n",
    "\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = tts(data, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, N_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "\n",
    "def conv(classes, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv(classes=N_CLASSES, input_shape=(28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "750/750 [==============================] - 35s 45ms/step - loss: 0.2723 - accuracy: 0.9163\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 30s 39ms/step - loss: 0.1525 - accuracy: 0.9535\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 31s 42ms/step - loss: 0.1350 - accuracy: 0.9572\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 34s 45ms/step - loss: 0.1180 - accuracy: 0.9639\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 33s 43ms/step - loss: 0.1085 - accuracy: 0.9659\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 30s 40ms/step - loss: 0.0956 - accuracy: 0.9694\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 32s 42ms/step - loss: 0.0898 - accuracy: 0.9711\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 35s 46ms/step - loss: 0.0862 - accuracy: 0.9715\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 32s 42ms/step - loss: 0.0763 - accuracy: 0.9748\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 27s 35ms/step - loss: 0.0710 - accuracy: 0.9761\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 33s 44ms/step - loss: 0.0634 - accuracy: 0.9791\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 33s 44ms/step - loss: 0.0603 - accuracy: 0.9800\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 34s 45ms/step - loss: 0.0576 - accuracy: 0.9812\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 29s 38ms/step - loss: 0.0557 - accuracy: 0.9820\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 36s 49ms/step - loss: 0.0526 - accuracy: 0.9825\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 30s 41ms/step - loss: 0.0474 - accuracy: 0.9847\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 32s 43ms/step - loss: 0.0439 - accuracy: 0.9855\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 37s 49ms/step - loss: 0.0421 - accuracy: 0.9858\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 32s 43ms/step - loss: 0.0420 - accuracy: 0.9851\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 31s 42ms/step - loss: 0.0395 - accuracy: 0.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a9a82d0a60>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(np.array(x_train), np.array(Y_train), batch_size=32, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(np.array(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.71666666666667\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    if np.argmax(pred[i]) == y_test[i]:\n",
    "        score+=1\n",
    "\n",
    "acc = ((score+0.0)/len(pred)*100)\n",
    "print(\"Accuracy: {acc}\".format(acc = ((score+0.0)/len(pred)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Get the current date and time\n",
    "current_time = datetime.now()\n",
    "\n",
    "# Format the date and time as a string (e.g., \"2022-01-01_12-30-45\")\n",
    "formatted_time = current_time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Combine the formatted time with a base file name\n",
    "base_file_name = \"./model/doodle\"\n",
    "\n",
    "file_name_with_timestamp = f\"{base_file_name}_{formatted_time}.h5\"\n",
    "\n",
    "model.save(file_name_with_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"./model/doodle.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded NumPy array:\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "[[8.60616505e-01 1.39372781e-01 1.06889265e-05]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicted: triangle\n"
     ]
    }
   ],
   "source": [
    "def load_numpy_array(file_path):\n",
    "    \"\"\"\n",
    "    Load a NumPy array from a file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: File path to load the array from.\n",
    "\n",
    "    Returns:\n",
    "    - numpy array: Loaded NumPy array.\n",
    "    \"\"\"\n",
    "    loaded_array = np.load(file_path)\n",
    "    return loaded_array\n",
    "\n",
    "# Example Usage:\n",
    "file_path = \"./user-data.npy\"\n",
    "loaded_array = load_numpy_array(file_path)\n",
    "print(\"Loaded NumPy array:\")\n",
    "visualize(denormalize(loaded_array))\n",
    "print(model.predict(loaded_array))\n",
    "pred = CLASSES[np.argmax(model.predict(loaded_array))]\n",
    "print(\"Predicted:\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def visualize_and_predict():\n",
    "    \"selects a random test case and shows the object, the prediction and the expected result\"\n",
    "    n = randint(0, len(x_test))\n",
    "    visualize(denormalize(np.reshape(x_test[n], (28, 28))))\n",
    "    pred = CLASSES[np.argmax(model.predict(np.array([x_test[n]])))]\n",
    "    actual = CLASSES[y_test[n]]\n",
    "    print(\"Actual:\", actual)\n",
    "    print(\"Predicted:\", pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "Actual: triangle\n",
      "Predicted: triangle\n"
     ]
    }
   ],
   "source": [
    "visualize_and_predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
